\documentclass[11pt]{article}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{An Outsiders' View of \\Domain-Specific Model/Language Engineering}
\author{William R. Cook and Tijs van der Storm}
%\date{}                                           % Activate to display a given date or no date

\begin{document}
\maketitle

\begin{abstract}
We believe that Model-Driven Development and Domain-Specific Languages
are two different communities working toward a similar goal.
The underlying idea is creating systems by specifying
\textit{what} they should do, rather than \textit{how} to do it. In order for these
systems to be realized efficiently, the specifications must be written
in a languages that are specialized to particular kinds of problems.
This essay draws parallels between the two communities, offers opinions
about what we think is likely to work, and identifies open research
questions. Integrating all these ideas might lead to a new
software development paradigm that is powerful enough to displace
objects as the primary tool for developing large parts of practical systems.
\end{abstract}


\section{Introduction}

We believe that a new software development paradigm
is struggling to be born. It appears in many guises
and contexts, under many names, and is as yet still
unformed and incomplete. We are not surprised at the 
struggles, for we do not believe that paradigms
arise from a single blinding flash of insight, 
but rather they come about by careful assembly of
many good ideas into a package that makes sense
and \textit{works}, as a whole, in some profound way. 
We believe we see initial attempts at creating such
an assemblage.
On the other hand, we suspect that
some of birth pains are self-inflicted,
because of confusion about the goal and narrowmindedness
in approaches to achieving this goal. 

To us, the essence of this new paradigm is a shift
toward descriptions of \textit{what} software should
do and away from \textit{how} it should do it, 
while still providing enough operational information
so that the desired behavior can be generated
automatically.

A description of ``what a system should do'' 
is normally called a \textit{specification} \cite{FOO}. Thus
it would be natural to assume we are talking
about general-purpose specification languages, 
like B~\cite{B} and Zed~\cite{Zed}, as the foundation for this new paradigm. 
But this is
not the case, because of the requirement at the end
of the above paragraph that desired behaviors can
be generated automatically. By this, we mean that
the \textit{specifications must be executable}, so that
the generated behaviors are sufficiently efficient
and reliable to be usable in practice.
There is as yet no general way to convert 
from a specification in a general-purpose 
specification language to an executable 
program\footnote{This kind of \textit{synthesis}
is an important research area \cite{DougSmith}, but it is not not
yet ready for widespread adoption.}. One way to
solve this problem in the short term is to limit the
expressiveness of the languages to a particular kind of problem.

We believe that \textit{executable special-purpose 
specification languages} are the next programming paradigm.
There are already many successful examples of this
approach, including grammars (Yacc~\cite{Yacc}), databases (SQL~\cite{SQL}),
spreadsheets (Excel~\cite{Excel}), security (XACML~\cite{XACML}), state
machines (StateCharts~\cite{Harel}), network protocols (NDLog \cite{NDLOG}), and user interfaces (XUL~\cite{XUL}).
These systems all allow users to specify what a
computation should do, without saying exactly how to
do it. They all have deep theory and optimization techniques
that make them expressive and efficient. But they are also
specialized to a particular task. 
There are many more examples in practical use, or experimental design.

There is a subtle point in our initial statement. 
We emphasize that \textit{behavior} is generated automatically, but
this does not necessarily mean that code is generated.
The behavior may
be generated by an \textit{interpreter}. The examples mentioned
above span the spectrum between interpretation and 
compilation.

The key question, for the development of a new paradigm,
is whether this approach can be
generalized so that it can be used to build complete
(or nearly complete) systems. Currently specialized specification
languages are used as small components of systems, but the
majority of the system is created using general-purpose code. 
The question is
whether this emphasis can be inverted, so that most of 
a system is build with specialized languages, with 
general-purpose used for the underlying language engines, or as 
application-specific code plugged in where necessary.
The success of this approach will depend in part on the
amount of regularity in the systems we want to build.

Given the goal, to move from \textit{how} towards \textit{what}
while still supporting executability, it is not surprising
that there is a lot of experimentation necessary. 
There are many problems that must be solved before this
vision is realized. In the remainder of this essay, we
try to observe the current situation, from both technical
and social viewpoints. We are outsiders, in that we do not owe
allegiance to any existing technology or approach. But the first
author has personal experience, in a commercial setting, with this
approach.

Since this is an essay, we take the 
liberty to give our opinion about the situation. 
We try to point out what we think is novel and significant
in the overall approach. We try to identify research
challenges and suggest new directions for research.

\section{Feeling the Elephant}

The story about the blind men feeling the elephant is an apt metaphor
for our current situation. We think there is one underlying idea
that appears in different forms depending on how you look at it.
There are multiple different communities working on what is 
essentially the same problem. The lack of communication and understanding
between these communities is a barrier to progress.

The two main communities working on special-purpose specification
languages are the communities associated with \textit{modeling}
and those associated with \textit{domain-specific languages} (DSL).
The fact that multiple groups are working on a similar problem
in a similar way is a good thing. It suggests that there really 
might be something there.

The modeling community grew out of work on the Unified Modeling
Language (UML) and publishes at the MODELS conference \cite{MODELS},
software engineering conferences, and sometimes in other
conferences related to the domain of application. There are many
variations on the modeling theme, including 
Model-Driven Architecture (MDA) \cite{MDA}, Data-Driven Software,
Open (Johnson) Object Architecture (???), [MORE].
``ModelWare''

The DSL community grew from the programming community, and
publishes at the conference on Generative Programming
and Component Engineering (GPCE) \cite{GPCE}, programming languages conferences, and sometimes in other
conferences related to the domain of application.
``GrammarWare''
There are many variants, especially around the issues of
embedded versus external DSLs, and whether syntactic extensions
are included in the idea. Domain-Specific Language Engineering.

What about other ideas?
   ``Domain-Driven Development"…. more about requirements / analysis / design
   ``OntologyWare"

Most PL people we talk to have no idea what is going on in the modeling
community. They generally dismiss the work as ``just pictures'' with
no semantic foundation or significance. Both grounds have had a tendency
to focus on syntax, leaving semantics as an exercise for the reader.
In what we follows, we discuss syntactic issues first, then
devote an entire section to semantics.

\section{Fundamental Concepts}

The concepts of ``model'' and ``meta-model'' are directly analogous to
``sentence''(aka program) and ``language'' in the PL/DSL community.
A model is an instance of a model-model in the same way that
a program is an instance of a DSL. In what follows we will use both
terminologies interchangeably.

\subsection{Domain Specificity}
Both approaches agree that they must develop languages/models for
specific problems or \textit{domains}. There is some confusion around
the word ``domain''. In business a \textit{vertical domain}
or \textit{vertical} is an area of application, for example finance,
education, health-care, or agriculture. On the other hand, A \textit{horizontal domain}
is an application area that applies to many verticals, for example
\textit{human resources}, \textit{security}, or \textit{conference management}.
The distinction is somewhat fuzzy. We believe that DSLs and models
are primarily focused on the horizontal kind of domain, rather than
verticals. However, there are some efforts to create truly vertical-specific
languages/models.

\subsection{Meta Meta Models}
The modeling community tends to put a lot of faith in the reflexive
application of the model/meta-model concept. That is, meta-models
are also models, which conform to meta-meta-models. The DSL community
also uses this idea, but it is not considered as fundamental or
essential. 

\subsection{Text Versus Graphics}
DSLs are typically textual
while models are typically graphical. However, there is nothing
essential about this distinction. From our viewpoint, both communities
seem to have a unhelpful attitude about the difference.
There is nothing magic about pictures, despite the hopes and 
desires of the modeling community. On the other hand, there is nothing
terrible about pictures, despite the criticism of some in the DSL
community (CITATIONS?).  They are just two different
ways of presenting information. As an example, consider grammars.
There are well-known presentations of grammars as BNF (text) and 
also as ``railroad diagrams" (pictures). In general the community has
determined that text is better. On the other hand, there are also
text and graphical presentations for database schemes/class libraries,
as Entity Relationship Diagrams (ERD) / Class Diagrams (in UML). 
In this case the consensus seems to be that the graphical version is
easier to read. But both representations are useful in different
contexts. A paradigm for domain-specific specification languages
should support both graphical and textual notations.

%   William: I think Model-Driven Development is ``next big thing", and it will replace objects as dominant paradigm
%
%Academic: Yeah, I don't understand that models stuff… its all just hooey and informal pictures

\subsection{Graphs}
  Trees look like trees but they are also graphs (with complex scoping issues, for Tree->Graph)
  Often matches natural structure of the problem
   Slogan that ``Trees are better for transformation" doesn't make sense, 
        because they have to derive graph structure during the transformation anyway
  give arguments why?
  They are different from traditional ``data structures"
     Sums of products: trees
     Objects: nodes with pointers, not ``graphs"
  Resist saying ``Everything is a graph"!!!

\section{Semantics}
  Transformation to models
     Code Generation is Bad
     (corollary: Code is a model, but it is not useful to think of it that way)
  Don't assume that ``transformation" is the only kind of semantics
  Interpretation
     partial evaluation for optimization (code generation)

\subsection{Integrating Languages/Models}
   Avoid slogans like ``Everything is a model"
   Avoid thinking that ``Everything is a…."  
       (If you have hammer, everything looks like a nail)
 
    ``Everything is not Something"
    ``Everything is not an instance of your pet theory"

\subsection{Model Transformation}
MT is Good, but not everything

  Many styles, with pluses and minuses (critique these)

    Functional
       Computed Attributes

    Imperative

    Rule-Based
      Term Rewriting
      Graph Rewriting
         Graphical Rules
         Textual Rules

  Challenges
    Scale up to real applications and real problems (e.g Grammar to LR1)
    Cyclicity
    Small-step versus Big-step: Incremental Changing structure versus creating new structure
    Creating structures versus Creating Analyses

\subsection{Don't be Afraid of Code!}

\subsection{Aspects}

An aspect is a change to the strategy for doing things.
It is a change to the model/language interpreter or compiler.


\section{Discussion}

To summarize the main points, we believe the essential goal 
is developing languages that

\begin{enumerate}
\item Describe \textit{what} should be computed without describing
precisely \textit{how}

\item Provide an effective strategy for converting the descriptions
into useful behaviors
\end{enumerate}

\subsection{Imperative versus Declarative}

  term rewriting
  
        rules are not ordered, but when we use it in practice we encode order into the data

	to get complex behaviors, you encode control flow/state into the terms
            Eelco's grammar normalizer is too complex to understand
            
  ``coherence": assignments are bad, but ordering them is

  Attribute grammars (and Excel) do not specify order
     (under the covers, there may be ``imperative" effects to make it happen"

  Cycles are a big issue (e.g. Excel), but we want to do graphs!

  ``How to Declare an Imperative"

  What really matters:

     Compositionality and Predictability are what matter.
         SQL is not very compositional (but the realtional algebra is)

     Locally-functional, globally imperative: Erlang, SQL.
        ``make a state in which these predicates are true"

     Viewing intermediate states a the problem
     what about constraint solving!!

\subsection{Why not Libraries?}
      Kolmagorov complexity
	http://research.microsoft.com/apps/pubs/default.aspx?id=69596
	http://lcsd05.cs.tamu.edu/papers/veldhuizen.pdf

Another Dimension of Modularity!

Its easy to see that some problems are not amenable to ordinary
modularization and code reuse. One simple example is this code:

\begin{verbatim}
printString("The time is ");
printInt(hours, 2, '0');
printChar(':');
printInt(minutes, 2, '0');
\end{verbatim}

At first glance, there doesn't seem to be 
much way to simplify this code, using normal library calls.
However, we all know that in C there is a function that
lets this be written more concisely:

\begin{verbatim}
printf("The time is %02d:%02d", hours, minutes);
\end{verbatim}

As a more extreme example, consider this code:

\begin{figure}
\begin{verbatim}
parseE(input) {
  if (`a' <= input.peek() && input.peek() <= `z') {
    char var = input.get();
    if (input.peek() == '+') {
      input.get();
      rest = parseE(input);
    } else
      error("foo");
  } else if (input.peek() == '(') {
    input.get();
    result = parseE(input);
    if (input.get() != ')')
      error("Expected )");
  } else
    error("foo");
\end{verbatim}
\caption{Example code}
\end{figure}

Normal modularity and reuse, which focus on code with
similar control flow but different data inputs, cannot
help simplify this code. Instead we need to realize
that the pattern being reused is more subtle. 

Its not at first clear that this could be generated by
compiling a grammar using a parsing strategy.

\begin{verbatim}
E = [a-z] | E `+' E | `(' E `)'
\end{verbatim}

Model-driven development is a kind of fourth dimension
of modularity. It lifts the program out in a different
direction.

\subsection{UML}
UML  is Not Helping

  Originally created to model OO designs.
  Overly complex.
  Not targeted at application models.
  Stereotypes are clumsy and complex.
  
  Missing models for User Interfaces, Security, Build Steps, etc...
  
  Give up the idea that there is a fixed set of essential models

\subsection{MDA}
PIM/PSM
  This distinction seems artificial


\section{Our Research Agenda}
Experimenting in
   DSL + Graphical/Textual + Graphs + Cyclic Functional Transformation + Interepreters + Partial Evaluation + Database feel

\section{Conclusions}



\end{document}  